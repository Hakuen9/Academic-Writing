\chapter{Introduction}

Tay, the artificial intelligence Twitter chatbot which was taken down 16 hours after its launch, was a project being developed by Microsoft Corporation. The chatbot was influenced by the design of Xiaoice, another chatbot developed by Microsoft and deployed in China. In 2015, Xiaoice chatted with 20 million users successfully, without any incidents. However this was not the case for Tay. Tay was taken offline since it started tweeting anti-semitic and racist remarks. Microsoft stated: “we became aware of a coordinated effort by some users to abuse Tay’s commenting skills to have Tay respond in inappropriate ways.”\cite{microsoftstatement}

This report will identify and research the technical as well as the ethical factors that could have led to the unexpected behaviour of the chatbot. Which led to it being taken offline. Microsoft Corporation requested a thorough root cause analysis on Tay AI. The conducted research serves as a recommendation for Microsoft Corporation. regarding the development of future artificial intelligence chatbots. 

Firstly, the theoretical framework will elaborate on two main topics of this report. Weak artificial intelligence and ethical software development. It will describe the chosen definitions and used sources of this report. Secondly, we will present our analysis in the Conducted Analysis section. This consists of a technical analysis as well as an ethical analysis. Furthermore, the findings will be summarized in the conclusion and it will explain which elements of an artificial intelligence chatbot should be taken into careful consideration when developing and testing an intelligent chatbot. 


