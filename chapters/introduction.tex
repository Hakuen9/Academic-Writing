\chapter{Introduction}

Tay, the artificial intelligence chatbot which was taken down 16 hours after its launch, was a project being developed by Microsoft corp. The chatbot was influenced by the design of Xiaoice, another chatbot developed by Microsoft. Xiaoice was deployed in China. In 2015, Xiaoice chatted with 20 million users successfully, without any incidents\cite{nytimes}. However this was not the case for Tay. Tay was taken offline since it started tweeting anti-semitic and racist remarks. Microsoft stated: “we became aware of a coordinated effort by some users to abuse Tay’s commenting skills to have Tay respond in inappropriate ways.”\cite{microsoftstatement}

[Purpose and position]: This report will identify and research the technical as well as the ethical factors that could have led to the unexpected behaviour of the chatbot. Which led to it being taken offline. Microsoft corp. requested for a thorough root cause analysis on Tay AI. The conducted research serves as a recommendation for Microsoft corp. regarding the development of future artificial intelligence chatbots.

Firstly, the theoretical framework will elaborate on two main topics of this report. Weak artificial intelligence and ethical software development. It will describe the chosen definitions and used sources of this report. Secondly, we will present our findings in the Facts and Findings section. This consists of a technical analysis as well as an ethical analysis. Furthermore, the findings will be summarized in the conclusion. Finally, the recommendation will explain which elements of an artificial intelligence chatbot should be taken into careful consideration when developing and testing an intelligent chatbot.

