\chapter{Problem Characterization}
In the first hours of the deployment of Tay, the responses of the chatbot were achieving more accuracy as more users interacted with the chatbot. The chatbot would base its answers on the vocabulary used in the conversations it had with its followers. After being online for several hours, the chatbot received more attention which led to an increasing number of twitter followers. This increase provides evidence of the risk of trolls, who could try to manipulate the chatbot.

After 16 hours, Tay was taken offline because it had expressed immoral thoughts which violated the guidelines of twitter. Moreover, It was clear that the behaviour was inappropriate so it had to be taken down, as a lot more people could have been offended/ hurt by those tweets. Microsoft stated that trolls caused Tay to tweet those thoughts \cite{microsoftstatement}. Which has supporting evidence, since Tay had to be “exposed” to those remarks by someone or something.

